{"nbformat_minor": 2, "cells": [{"source": "# Imports", "cell_type": "markdown", "metadata": {}}, {"execution_count": 1, "cell_type": "code", "source": "from pyspark.sql import *\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import *\nfrom pyspark import SparkContext\nsc = SparkContext.getOrCreate()\nsqlContext = SQLContext(sc)\nimport pandas as pd", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Starting Spark application\n"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>34</td><td>application_1643288788512_0039</td><td>pyspark3</td><td>idle</td><td><a target=\"_blank\" href=\"http://hn1-grupo1.rj5uyp0hv1qetaiteuz3n1cisg.zrhx.internal.cloudapp.net:8088/proxy/application_1643288788512_0039/\">Link</a></td><td><a target=\"_blank\" href=\"http://wn2-grupo1.rj5uyp0hv1qetaiteuz3n1cisg.zrhx.internal.cloudapp.net:30060/node/containerlogs/container_1643288788512_0039_01_000001/livy\">Link</a></td><td>\u2714</td></tr></table>"}, "metadata": {}}, {"output_type": "stream", "name": "stdout", "text": "SparkSession available as 'spark'.\n"}], "metadata": {"scrolled": false, "cell_status": {"execute_time": {"duration": 819.555908203125, "end_time": 1643624998983.494}}, "collapsed": false}}, {"source": "# Leemos el fichero de usuarios", "cell_type": "markdown", "metadata": {}}, {"execution_count": 2, "cell_type": "code", "source": "df1 = spark.read.format(\"csv\").load(\"/data/userid-profile.tsv\", sep='\\t', header=True, inferSchema=True)", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 48045.3369140625, "end_time": 1643625048993.268}}, "collapsed": true}}, {"source": "# Pasamos el DF a Pandas para operar con el", "cell_type": "markdown", "metadata": {}}, {"execution_count": 3, "cell_type": "code", "source": "pandasDFusuarios = df1.toPandas()", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 4231.944091796875, "end_time": 1643625057325.803}}, "collapsed": true}}, {"source": "# Obtenemos los que no tienen id, pais o fecha de registro", "cell_type": "markdown", "metadata": {}}, {"execution_count": 4, "cell_type": "code", "source": "df_usuarios_sin_datos = pandasDFusuarios[pandasDFusuarios['id'].isnull() | pandasDFusuarios['country'].isnull() | pandasDFusuarios['registered'].isnull() ]", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 352.947021484375, "end_time": 1643625064205.598}}, "collapsed": false}}, {"source": "# Nos quedamos con los que tienen todos los datos", "cell_type": "markdown", "metadata": {}}, {"execution_count": 5, "cell_type": "code", "source": "df_usuarios_completos = pandasDFusuarios\ndf_usuarios_completos.drop(df_usuarios_sin_datos.index, inplace = True)", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 308.248046875, "end_time": 1643625068882.039}}, "collapsed": true}}, {"source": "# El Panda lo paso a DF para escribirlo en fichero y tabla Hive", "cell_type": "markdown", "metadata": {}}, {"execution_count": 6, "cell_type": "code", "source": "sparkDF=spark.createDataFrame(df_usuarios_completos)", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 1347.7958984375, "end_time": 1643625073837.133}}, "collapsed": true}}, {"source": "# Escribo en fichero el resultado", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "sparkDF.write.format(\"csv\").save('wasb://containergrupo1clusterspark@grupo1clusterhdistorage.blob.core.windows.net/data/userid-profile-clear.csv',header = 'true')", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 9428.126953125, "end_time": 1643621434781.93}}, "collapsed": true}}, {"source": "# Creo la estructura de la tabla HIVE", "cell_type": "markdown", "metadata": {}}, {"execution_count": 19, "cell_type": "code", "source": "%%sql -q\nCREATE TABLE IF NOT EXISTS useridProfile ( \n                    id string, \n                    gender string, \n                    age int,\n                    country string,\n                    registered string)", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 19603.4951171875, "end_time": 1643624388758.899}}, "collapsed": true}}, {"source": "# Guardo los datos en la tabla", "cell_type": "markdown", "metadata": {}}, {"execution_count": 8, "cell_type": "code", "source": "dfw = DataFrameWriter(sparkDF)\ndfw.insertInto('useridProfile', overwrite=True)", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 15543.96484375, "end_time": 1643625127112.639}}, "collapsed": true}}, {"source": "# Compruebo para ver que hay datos en la tabla", "cell_type": "markdown", "metadata": {}}, {"execution_count": 9, "cell_type": "code", "source": "datosdf = spark.sql(\"\"\"\nSELECT * \nFROM useridProfile \n\"\"\")\ndatosdf.show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+-----------+------+---+------------------+------------+\n|         id|gender|age|           country|  registered|\n+-----------+------+---+------------------+------------+\n|user_000001|     m|  0|             Japan|Aug 13, 2006|\n|user_000002|     f|  0|              Peru|Feb 24, 2006|\n|user_000003|     m| 22|     United States|Oct 30, 2005|\n|user_000005|     m|  0|          Bulgaria|Jun 29, 2006|\n|user_000006|  null| 24|Russian Federation|May 18, 2006|\n|user_000007|     f|  0|     United States|Jan 22, 2006|\n|user_000008|     m| 23|          Slovakia|Sep 28, 2006|\n|user_000009|     f| 19|     United States|Jan 13, 2007|\n|user_000010|     m| 19|            Poland| May 4, 2006|\n|user_000011|     m| 21|           Finland| Sep 8, 2005|\n|user_000012|     f| 28|     United States|Mar 30, 2005|\n|user_000013|     f| 25|           Romania|Sep 25, 2006|\n|user_000015|  null| 21|     Cote D'Ivoire| Oct 3, 2006|\n|user_000016|     m|  0|    United Kingdom| Aug 5, 2005|\n|user_000017|     m| 22|           Morocco|Aug 27, 2007|\n|user_000018|  null| 22|    United Kingdom|Aug 26, 2005|\n|user_000019|     f| 29|            Mexico|Nov 10, 2005|\n|user_000020|     f| 27|           Germany|Jul 24, 2006|\n|user_000021|     m| 27|            Canada|Mar 16, 2005|\n|user_000022|     m| 38|    United Kingdom|May 14, 2006|\n+-----------+------+---+------------------+------------+\nonly showing top 20 rows"}], "metadata": {"cell_status": {"execute_time": {"duration": 7467.554931640625, "end_time": 1643625134608.66}}, "collapsed": false}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "PySpark3", "name": "pyspark3kernel", "language": ""}, "language_info": {"mimetype": "text/x-python", "pygments_lexer": "python3", "name": "pyspark3", "codemirror_mode": {"version": 3, "name": "python"}}}}